<div align="center">
<img src='./images/Header.png' alt='DroidScope Autonomous UX Exploration & Analysis Tool Based on Droidrun Framework'>


<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg?style=flat-square&logo=python" alt="Python">
  <img src="https://img.shields.io/badge/Flask-2.x-green.svg?style=flat-square&logo=flask" alt="Flask">
  <img src="https://img.shields.io/badge/DroidRun-SDK-orange.svg?style=flat-square" alt="DroidRun">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square" alt="License">
</p>

<p align="center">
An autonomous UX exploration and analysis tool with a sleek monochrome web interface.<br>
Uses <a href="https://github.com/droidrun/droidrun">DroidRun SDK</a> automation to act as an intelligent UX tester, exploring apps and<br>
generating comprehensive analysis reports with real-time execution logs and professional metrics.
</p>

</div>

---

## ğŸ†• What's New

### Latest Updates (February 2026)

<table>
<tr>
<td width="40%"><b>ğŸ”„ Advanced Comparison View</b></td>
<td width="60%">
Complete redesign of the comparison screen with:
<ul>
<li>Common features identification across all apps</li>
<li>Distinct/unique features per app</li>
<li>Detailed "What went good" sections</li>
<li>"What's bad" with severity categorization (High/Medium/Low)</li>
<li>Enhanced metrics: complexity score, navigation depth, screens discovered</li>
<li>Color-coded UX score visualization (green/yellow/red)</li>
<li>Summary statistics dashboard</li>
<li>Improved card layout with better visual hierarchy</li>
</ul>
</td>
</tr>
<tr>
<td><b>ğŸ“Š Enhanced Data Extraction</b></td>
<td>
Backend improvements to extract more comparison data:
<ul>
<li>Feature extraction from core flows, reused patterns, and positive aspects</li>
<li>Automated common vs. distinct feature analysis</li>
<li>Issue categorization by severity</li>
<li>Error handling quality ratings</li>
</ul>
</td>
</tr>
<tr>
<td><b>ğŸ¨ UI/UX Improvements</b></td>
<td>
<ul>
<li>Better visual distinction between apps in comparison</li>
<li>Progress bars for UX scores</li>
<li>Scrollable sections for long lists</li>
<li>Responsive grid layouts (adapts to 1-5 apps)</li>
<li>Improved badge styling and color schemes</li>
</ul>
</td>
</tr>
</table>

---

## ğŸ“š Quick Reference

<table>
<tr>
<td width="50%" valign="top">

### ğŸš€ Getting Started (First Time)

```powershell
# 1. Create & activate virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure API key
copy .env.example .env
# Edit .env and add your API_KEY

# 4. Verify setup
python verify_setup.py

# 5. Launch!
python app.py
```

**Then:** Open http://localhost:5000

</td>
<td width="50%" valign="top">

### ğŸ”„ Daily Usage (Already Set Up)

```powershell
# 1. Activate environment
.\venv\Scripts\Activate.ps1

# 2. Connect device
adb devices  # Verify device shown

# 3. Launch server
python app.py

# 4. When done
deactivate
```

**Common Commands:**
```powershell
droidrun ping          # Test device connection
python verify_setup.py # Check configuration
```

</td>
</tr>
</table>

---

## ğŸ” Overview

<table>
<tr>
<td width="50%">

**DroidScope** leverages the DroidRun framework to automatically explore mobile applications, discover navigable screens, record transitions, and produce structured UX flow maps with AI-powered analysis.

</td>
<td width="50%">

**Features** a Flask-based web interface with real-time progress tracking, live terminal logs, and category-aware intelligence that tailors testing to your app type.

</td>
</tr>
</table>

---

## âœ¨ Features

<table>
<tr>
<td width="50%" valign="top">

### ğŸ¨ Interface & UX
- **Monochrome Design** - Clean black & white theme with grid background
- **Live Execution Logs** - Real-time terminal events with agent reasoning
- **Dual SSE Streams** - Separate progress & log updates
- **Visual Reports** - Interactive Chart.js visualizations with 8 stat cards
- **Card-Based Layout** - Professional result cards with metadata
- **Rounded Corners** - Modern UI with consistent border-radius
- **Advanced Comparison** - Side-by-side app comparison with detailed metrics

</td>
<td width="50%" valign="top">

### ğŸ¤– Intelligence & Analysis
- **Category-Aware** - Context-specific testing goals
- **Comprehensive Metrics** - 12 UX categories analyzed
- **Professional Reports** - Interaction feedback, visual hierarchy, consistency tracking
- **Safety First** - Avoids destructive actions
- **Device Verification** - Pre-flight droidrun ping
- **Schema-Agnostic** - Backward & forward compatible JSON handling
- **Multi-App Analysis** - Compare features, issues, and UX scores across apps

</td>
</tr>
<tr>
<td width="50%" valign="top">

### âš™ï¸ Configuration
- **Depth Control** - Adjustable (3-12 levels)
- **Category Selection** - 13 app categories
- **Dynamic LLM Config** - Model & provider from environment variables
- **Flexible API** - Supports any OpenAI-compatible endpoint

</td>
<td width="50%" valign="top">

### ğŸš€ Automation
- **Autonomous Navigation** - AI explores like humans
- **Breadth-First Search** - Comprehensive coverage
- **Structured Output** - Navigation graph JSON + analysis blocks

</td>
</tr>
<tr>
<td width="50%" valign="top">

### ğŸ“Š Comparison Features (NEW)
- **Common Features** - Identifies shared patterns across apps
- **Distinct Features** - Highlights unique aspects per app
- **Issue Analysis** - Categorizes problems by severity (High/Medium/Low)
- **Positive Insights** - What went well in each app
- **Metric Comparison** - Complexity, depth, screens, error handling
- **Visual Charts** - Color-coded UX score comparison graphs

</td>
<td width="50%" valign="top">

### ğŸ—„ï¸ Data Management
- **SQLite Database** - Persistent storage for all explorations
- **Library View** - Browse and filter past results
- **Stage Tracking** - Multi-stage exploration with progress
- **Persona Analysis** - Test from different user perspectives
- **Export & Compare** - Save comparison snapshots

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

<div align="center">

### **Commands to Launch**

</div>

```powershell
python app.py             # ğŸš€ Start server
# ğŸŒ Open http://localhost:5000
```

---

## ğŸ¨ Interface Preview

<div align="center">

### **Main Interface**
<img src="./images/ui 3.png" alt="UX Analysis Results" width="800">

### **Real-Time Execution Logs**
<img src="./images/ui 2.png" alt="Live Terminal Logs" width="800">

</div>

---

## ğŸ“¦ Setup

> **â±ï¸ Setup Time:** ~5 minutes | **ğŸ’¡ Tip:** Run `python verify_setup.py` after setup to check everything

<details open>
<summary><b>1ï¸âƒ£ Prerequisites</b></summary>

Before starting, ensure you have:

- âœ… **Python 3.8+** installed ([Download](https://python.org))
- âœ… **Android device/emulator** with USB debugging enabled
- âœ… **ADB** working (`adb devices` should list your device)
- âœ… **Internet connection** for API calls

**Quick Check:**
```powershell
python --version  # Should be 3.8 or higher
adb devices       # Should show your device
```

</details>

<details open>
<summary><b>2ï¸âƒ£ Clone/Download Repository</b></summary>

If you haven't already:

```powershell
git clone <repository-url>
cd DroidScope
```

Or download and extract the ZIP file, then navigate to the folder in PowerShell.

</details>

<details open>
<summary><b>3ï¸âƒ£ Create Virtual Environment</b></summary>

**Why?** Keeps dependencies isolated and prevents conflicts with other Python projects.

```powershell
python -m venv venv
```

This creates a `venv` folder containing an isolated Python environment.

</details>

<details open>
<summary><b>4ï¸âƒ£ Activate Virtual Environment</b></summary>

**Windows PowerShell:**
```powershell
.\venv\Scripts\Activate.ps1
```

**Windows CMD:**
```cmd
venv\Scripts\activate.bat
```

**Expected Result:** Your terminal prompt should now show `(venv)` at the beginning.

**If you encounter an execution policy error:**
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

</details>

<details open>
<summary><b>5ï¸âƒ£ Install Dependencies</b></summary>

**With activated venv:**
```powershell
pip install -r requirements.txt
```

This installs:
- `flask` - Web framework
- `droidrun` - Android automation
- `python-dotenv` - Environment variable management
- Other required packages

**To verify installation:**
```powershell
pip list
```

</details>

<details open>
<summary><b>6ï¸âƒ£ Install DroidRun Framework</b></summary>

**If not already installed:**

```powershell
pip install droidrun
```

**Verify DroidRun:**
```powershell
droidrun --version
droidrun ping  # Should detect your device
```

**Troubleshooting:**
- If `droidrun ping` fails, check device connection with `adb devices`
- Ensure USB debugging is enabled on your device

ğŸ“– **Learn more:** [DroidRun Documentation](https://github.com/droidrun/droidrun)

</details>

<details open>
<summary><b>7ï¸âƒ£ Configure Environment Variables</b></summary>

**Create `.env` file in project root:**

1. **Copy the example file:**
   ```powershell
   copy .env.example .env
   ```

2. **Edit `.env` with your API key:**
   ```env
   # Required: Your OpenRouter API Key
   API_KEY=sk-or-v1-your_actual_key_here
   
   # Optional: LLM Configuration (defaults shown)
   LLM_MODEL=mistralai/devstral-2512:free
   LLM_API_BASE=https://openrouter.ai/api/v1
   ```

3. **Get your API key:**
   - Visit: https://openrouter.ai/keys
   - Sign up (free tier available)
   - Create API key
   - Copy and paste into `.env`

**Using OpenAI instead?**
```env
API_KEY=sk-your_openai_key_here
LLM_MODEL=gpt-4o-mini
LLM_API_BASE=https://api.openai.com/v1
```

**Security Note:** Never commit `.env` to version control (it's in `.gitignore`)

</details>

<details open>
<summary><b>8ï¸âƒ£ Verify Setup</b></summary>

**Run the verification script:**
```powershell
python verify_setup.py
```

**This checks:**
- âœ… `.env` file exists with API_KEY
- âœ… Device connection via `droidrun ping`
- âœ… All required directories exist
- âœ… All prompt files present
- âœ… Frontend files (HTML, CSS, JS)
- âœ… Python packages installed

**If all checks pass âœ…, you're ready to launch!**

</details>

---

## ğŸ¯ Usage

### ğŸŒ Web Interface (Recommended)

**Start the server:**
```powershell
python app.py
```

**Expected output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ”­ DroidScope Starting...     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Running on http://127.0.0.1:5000
```

Then open **http://localhost:5000** in your browser (Chrome/Edge recommended).

---

### ğŸ“ Step-by-Step Testing Guide

<table>
<tr>
<th width="10%">Step</th>
<th width="30%">Action</th>
<th width="60%">Details</th>
</tr>
<tr>
<td align="center">1ï¸âƒ£</td>
<td><b>Enter App Name</b></td>
<td>Type the display name of the app (e.g., "Instagram", "WhatsApp")<br><i>Not the package name!</i></td>
</tr>
<tr>
<td align="center">2ï¸âƒ£</td>
<td><b>Select Category</b></td>
<td>Choose from 13 categories - affects which UX patterns are tested<br>
<details>
<summary>Available categories</summary>

- Social Media
- E-commerce
- Food Delivery
- Messaging
- Finance/Banking
- Productivity
- Entertainment
- Education
- Health & Fitness
- Travel
- News
- Utilities
- Other

</details>
</td>
</tr>
<tr>
<td align="center">3ï¸âƒ£</td>
<td><b>Set Exploration Depth</b></td>
<td>
Use slider (3-12):
<ul>
<li><b>3-4:</b> Quick test (~3-5 min) - Surface-level screens</li>
<li><b>5-7:</b> Balanced (~10-15 min) - Recommended for most apps</li>
<li><b>8-12:</b> Deep dive (~20-30 min) - Comprehensive testing</li>
</ul>
<i>Note: Steps = Depth Ã— 15</i>
</td>
</tr>
<tr>
<td align="center">4ï¸âƒ£</td>
<td><b>Click "Start UX Test"</b></td>
<td>Watch real-time progress and terminal logs<br>
âœ… Safe to browse away - test continues in background</td>
</tr>
<tr>
<td align="center">5ï¸âƒ£</td>
<td><b>View Results</b></td>
<td>
<ul>
<li>ğŸ“Š Interactive Chart.js visualizations</li>
<li>ğŸ“ˆ 8 metric stat cards</li>
<li>ğŸ“ Executive summary</li>
<li>âœ… Strengths found</li>
<li>âš ï¸ Issues categorized</li>
<li>ğŸ’¡ Actionable recommendations</li>
</ul>
</td>
</tr>
<tr>
<td align="center">6ï¸âƒ£</td>
<td><b>Compare Results (NEW)</b></td>
<td>
Navigate to the Compare tab to:
<ul>
<li>ğŸ”„ Compare multiple apps side-by-side</li>
<li>ğŸ¯ View common vs. distinct features</li>
<li>âœ… See what went good across apps</li>
<li>âŒ Identify issues by severity level</li>
<li>ğŸ“Š Compare UX scores, complexity, and depth</li>
<li>ğŸ’¾ Save comparison snapshots</li>
</ul>
</td>
</tr>
</table>

---

### ğŸ¬ What Happens During Testing

**Progress Phases:**

```
 0% â†’ 10%   Generating category-specific testing goals
10% â†’ 20%   Initializing DroidRun agent on device
20% â†’ 60%   ğŸ¤– Active exploration (this takes longest)
             â”œâ”€ AI navigates through app
             â”œâ”€ Takes screenshots
             â”œâ”€ Records UI hierarchy
             â””â”€ Builds navigation graph
60% â†’ 75%   Loading exploration report
75% â†’ 80%   ğŸ” Running UX analysis with LLM
80% â†’ 90%   Generating visualizations
90% â†’ 100%  Rendering results
100% âœ…     Complete!
```

**Real-Time Features:**
- ğŸ“Š **Progress bar** - Shows completion percentage
- ğŸ“‹ **Terminal logs** - Live execution events with color coding
  - ğŸ”µ Info (gray) - General updates
  - ğŸŸ¢ Success (green) - Completed actions
  - ğŸŸ¡ Warning (yellow) - Non-critical issues
  - ğŸ”´ Error (red) - Problems encountered
- ğŸ§  **Agent reasoning** - See actual LLM decision-making

---

## ğŸ“Š Analysis Output

### Generated Files

| File | Description |
|------|-------------|
| `agent_result.txt` | Raw exploration results with markdown report |
| `ux_analysis_blocks.json` | Comprehensive UX analysis with 12 metric categories |
| `trajectories/[session]/` | Session data including screenshots and actions |
| `droidscope.db` | SQLite database with all exploration results and comparisons |

### Metrics Analyzed

<table>
<tr>
<td width="50%" valign="top">

**Navigation & Structure**
- Total screens discovered
- Max depth reached
- Orphan screens
- Hub screen count
- Dead elements percentage

</td>
<td width="50%" valign="top">

**Interaction & Feedback**
- Visible feedback rate
- Silent failures count
- CTA visibility score (1-10)
- Preventable errors
- Loading state presence

</td>
</tr>
<tr>
<td width="50%" valign="top">

**Comparison Metrics (NEW)**
- Common features across apps
- Unique/distinct features per app
- Issue distribution by severity
- Positive patterns identified
- Error handling quality rating

</td>
<td width="50%" valign="top">

**Complexity & Coverage**
- Complexity score (1-10)
- Average navigation depth
- Screens discovered count
- Successful action percentage
- Clickable elements found

</td>
</tr>
</table>

### Report Sections

- **Executive Summary** - Overall UX maturity assessment
- **Key Metrics** - 3 charts + 8 stat cards with quantified data
- **Strengths** - Positive UX patterns with evidence
- **Issues** - Categorized problems with severity, location, and impact
- **Recommendations** - Prioritized improvements with effort estimates

### Comparison View (NEW)

The enhanced comparison screen allows you to:

<table>
<tr>
<td width="50%" valign="top">

**Feature Analysis**
- ğŸŸ¢ **Common Features** - Patterns shared across all compared apps
- ğŸ”µ **Distinct Features** - Unique aspects of each app
- ğŸ“Š **Feature Extraction** - From core flows, reused patterns, and positive aspects

</td>
<td width="50%" valign="top">

**Quality Assessment**
- âœ… **What Went Good** - Top positive aspects with descriptions
- âŒ **What's Bad** - Issues categorized by severity (High/Medium/Low)
- ğŸ“ˆ **Metrics Comparison** - UX score, complexity, depth, screens
- ğŸ¯ **Error Handling** - Quality ratings across apps

</td>
</tr>
</table>

**Comparison Features:**
- Side-by-side app cards with color-coded UX scores
- Visual progress bars (green/yellow/red based on score)
- Issue severity breakdown with counts
- Summary statistics (avg score, total issues, total positives)
- Interactive chart with color-coded bars
- Responsive grid layout (up to 5 apps)

---

## âœ… Launch Checklist

### ğŸ” Pre-Launch Verification

Run the verification script to check all dependencies:

```powershell
python verify_setup.py
```

<table>
<tr>
<th>Check</th>
<th>Description</th>
</tr>
<tr>
<td>âœ…</td>
<td><code>.env</code> file exists with API_KEY</td>
</tr>
<tr>
<td>âœ…</td>
<td>Device connection via <code>droidrun ping</code></td>
</tr>
<tr>
<td>âœ…</td>
<td>All directories exist (templates, static, prompts)</td>
</tr>
<tr>
<td>âœ…</td>
<td>All prompt files present</td>
</tr>
<tr>
<td>âœ…</td>
<td>Frontend files ready (HTML, CSS, JS)</td>
</tr>
<tr>
<td>âœ…</td>
<td>Python packages installed</td>
</tr>
</table>

### ğŸš€ Launch Sequence

<table>
<tr>
<th width="30%">Step</th>
<th>Command</th>
</tr>
<tr>
<td><b>1. Verify Setup</b><br>(recommended)</td>
<td>

```powershell
python verify_setup.py
```

</td>
</tr>
<tr>
<td><b>2. Start Server</b></td>
<td>

```powershell
python app.py
```

You should see:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ”­ DroidScope Starting...     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</td>
</tr>
<tr>
<td><b>3. Open Browser</b></td>
<td>Navigate to <code>http://localhost:5000</code></td>
</tr>
</table>

### ğŸ§ª First Test Run

<table>
<tr>
<th>Field</th>
<th>Example</th>
</tr>
<tr>
<td>App Name</td>
<td>"Instagram", "Blinkit", "WhatsApp"</td>
</tr>
<tr>
<td>Category</td>
<td>"Social Media", "Food Delivery", "Messaging"</td>
</tr>
<tr>
<td>Depth Slider</td>
<td>6 (recommended for balanced testing)</td>
</tr>
</table>

> **ğŸ“Œ Note**: Depth â‰  Steps. Depth controls navigation distance, not total actions.

**What to Watch:**
- ğŸ“Š Progress bar for completion percentage
- ğŸ“‹ Terminal logs for real-time execution events
- ğŸ“ˆ Interactive results with charts and insights

### ğŸ“Š Expected Progress Phases

```
10%  - Generating category context
20%  - Initializing DroidRun agent  
30%  - Starting exploration (may take 5-15 min)
30%  - Starting exploration (may take 5-15 min)
60%  - Exploration complete
75%  - Loading report
80%  - Running UX analysis
90%  - Generating visualizations
100% - Complete!
```

### ğŸ”§ Troubleshooting

<details>
<summary><b>âŒ Device not connected</b></summary>

**Symptoms:**
- `droidrun ping` fails or hangs
- "No device connected" error
- Exploration doesn't start

**Solutions:**

1. **Check ADB Connection**
   ```powershell
   adb devices
   ```
   You should see your device listed. If not:
   
2. **Restart ADB Server**
   ```powershell
   adb kill-server
   adb start-server
   adb devices
   ```

3. **For Physical Devices:**
   - Enable USB Debugging in Developer Options
   - Check USB cable (use data cable, not charge-only)
   - Allow USB debugging on device popup
   - Try different USB ports

4. **For Emulators:**
   - Ensure emulator is fully booted
   - Try restarting the emulator
   - Check if emulator shows in `adb devices`
   
5. **Verify DroidRun Installation**
   ```powershell
   droidrun --version
   droidrun ping
   ```
   If DroidRun is not installed:
   ```powershell
   pip install droidrun
   ```

6. **Multiple Devices:**
   If you have multiple devices, specify one:
   ```powershell
   adb devices  # List all devices
   # Use the device ID in your commands
   ```

</details>

<details>
<summary><b>ğŸ”‘ Missing API key</b></summary>

**Symptoms:**
- "API key not found" error
- LLM requests fail
- Analysis doesn't generate

**Solutions:**

1. **Create `.env` File**
   
   In your project root, create a file named `.env` (not `.env.txt`):
   
   ```env
   API_KEY=sk-or-v1-your_openrouter_key_here
   LLM_MODEL=mistralai/devstral-2512:free
   LLM_API_BASE=https://openrouter.ai/api/v1
   ```

2. **Get Your API Key**
   
   - Visit: https://openrouter.ai/keys
   - Sign up/login
   - Generate a new API key
   - Copy the key (starts with `sk-or-v1-`)

3. **Using OpenAI Instead**
   
   If you prefer OpenAI:
   ```env
   API_KEY=sk-your_openai_key_here
   LLM_MODEL=gpt-4o-mini
   LLM_API_BASE=https://api.openai.com/v1
   ```

4. **Verify API Key**
   
   Run the verification script:
   ```powershell
   python verify_setup.py
   ```
   
   It will check if your `.env` file is properly configured.

5. **Common Issues:**
   - âŒ File named `.env.txt` instead of `.env`
   - âŒ API key has extra spaces
   - âŒ Missing `API_KEY=` prefix
   - âŒ File in wrong directory (must be in project root)

6. **Test API Connection**
   ```powershell
   # Run a simple test
   python -c "from dotenv import load_dotenv; import os; load_dotenv(); print('API Key loaded:', 'Yes' if os.getenv('API_KEY') else 'No')"
   ```

</details>

<details>
<summary><b>ğŸ”Œ Port already in use</b></summary>

**Symptoms:**
- "Address already in use" error
- "OSError: [WinError 10048]"
- Flask fails to start

**Solutions:**

1. **Find Process Using Port 5000**
   
   ```powershell
   netstat -ano | findstr :5000
   ```
   
   This shows the PID (Process ID) of the program using the port.

2. **Kill the Process**
   
   ```powershell
   taskkill /PID <process_id> /F
   ```
   
   Replace `<process_id>` with the number from step 1.

3. **Change DroidScope Port**
   
   Edit [app.py](app.py) (at the bottom):
   
   ```python
   if __name__ == '__main__':
       app.run(debug=True, port=5001)  # Changed from 5000 to 5001
   ```
   
   Then access at: `http://localhost:5001`

4. **Use Any Available Port**
   
   ```python
   # app.py - Let Flask choose a free port
   if __name__ == '__main__':
       app.run(debug=True, port=0)  # Automatically finds free port
   ```
   
   Flask will print the actual port it's using.

5. **Close Other Instances**
   
   Make sure you don't have multiple terminal windows running `python app.py`

</details>

<details>
<summary><b>ğŸ Python/Virtual Environment Issues</b></summary>

**Symptoms:**
- "python: command not found"
- "venv not activating"
- Packages not found after installation

**Solutions:**

1. **Check Python Installation**
   ```powershell
   python --version
   # Should show Python 3.8 or higher
   ```
   
   If not installed, download from: https://python.org

2. **Execution Policy Error (Windows)**
   ```powershell
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```

3. **Recreate Virtual Environment**
   ```powershell
   # Remove old venv
   Remove-Item -Recurse -Force venv
   
   # Create new one
   python -m venv venv
   .\venv\Scripts\Activate.ps1
   pip install -r requirements.txt
   ```

4. **Packages Not Found**
   
   Ensure venv is activated (you should see `(venv)` in terminal):
   ```powershell
   .\venv\Scripts\Activate.ps1
   pip list  # Check installed packages
   ```

</details>

<details>
<summary><b>ğŸ“± App Not Installed/Opening</b></summary>

**Symptoms:**
- "App not found" error
- Wrong app opens
- App crashes immediately

**Solutions:**

1. **Check App Installation**
   ```powershell
   adb shell pm list packages | findstr instagram  # Replace with your app
   ```

2. **Install App on Device**
   ```powershell
   adb install path/to/app.apk
   ```

3. **Use Correct Package Name**
   
   When entering app name, use the display name (e.g., "Instagram", not "com.instagram.android")

4. **Grant Permissions**
   
   Some apps need permissions. Grant them manually or:
   ```powershell
   adb shell pm grant com.yourapp.package android.permission.PERMISSION_NAME
   ```

</details>

<details>
<summary><b>âš¡ Slow Performance/Timeouts</b></summary>

**Symptoms:**
- Exploration takes too long
- "Timeout" errors
- App freezes during testing

**Solutions:**

1. **Reduce Exploration Depth**
   
   Use slider to set depth to 3-5 for faster tests

2. **Check Device Performance**
   
   - Close background apps
   - Use a more powerful emulator configuration
   - Increase emulator RAM in AVD settings

3. **Network Issues**
   
   Ensure stable internet for API calls to LLM

4. **Use Faster LLM Model**
   
   Edit `.env`:
   ```env
   LLM_MODEL=mistralai/devstral-2512:free  # Faster, free model
   ```

</details>

<details>
<summary><b>ğŸ“Š Analysis Not Generating</b></summary>

**Symptoms:**
- Progress stops at 60%
- No analysis report
- Empty results page

**Solutions:**

1. **Check Terminal Logs**
   
   Look for error messages in the terminal where you ran `python app.py`

2. **Verify Report Files**
   ```powershell
   # Check if exploration generated output
   dir agent_result.txt
   dir ux_analysis_blocks.json
   ```

3. **API Rate Limits**
   
   If using free tier, you might hit rate limits. Wait a few minutes and try again.

4. **Re-run Analysis Manually**
   ```powershell
   python ux_analyzer.py
   ```

5. **Check Prompt Files**
   
   Ensure all files in `prompts/` folder exist:
   - `agent_goal.txt`
   - `analysis_prompt_v2.txt`
   - `html_generation_prompt.txt`

</details>

<details>
<summary><b>ğŸŒ Browser/UI Issues</b></summary>

**Symptoms:**
- Page not loading
- Logs not showing
- Charts not rendering

**Solutions:**

1. **Clear Browser Cache**
   
   Press `Ctrl + Shift + R` to hard refresh

2. **Check Browser Console**
   
   Press `F12` â†’ Console tab to see JavaScript errors

3. **Try Different Browser**
   
   Chrome/Edge recommended for best compatibility

4. **Check Network Tab**
   
   F12 â†’ Network â†’ Look for failed SSE connections to `/api/progress` or `/api/logs`

5. **Disable Browser Extensions**
   
   Ad blockers might interfere with SSE streams

</details>

---

## ğŸ“ Project Structure

```
DroidScope/
â”œâ”€â”€ app.py                      # Flask web server with SSE & comparison API
â”œâ”€â”€ staged_runner.py            # Multi-stage exploration runner
â”œâ”€â”€ exploration_runner.py       # Category-aware exploration (legacy)
â”œâ”€â”€ ux_analyzer.py              # UX analysis engine
â”œâ”€â”€ database.py                 # SQLite database operations
â”œâ”€â”€ json_to_db.py               # Import explorations to database
â”œâ”€â”€ verify_setup.py             # Pre-flight checks
â”œâ”€â”€ utils.py                    # Shared utilities
â”œâ”€â”€ droidscope.db               # SQLite database (auto-created)
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index_new.html          # Main web UI with comparison view
â”‚   â””â”€â”€ index.html              # Legacy UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script_new.js           # Frontend logic + SSE + comparison
â”‚   â”œâ”€â”€ script.js               # Legacy frontend
â”‚   â””â”€â”€ icons/                  # UI icons
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ agent_goal.txt          # Exploration instructions
â”‚   â”œâ”€â”€ analysis_prompt_v2.txt  # UX analysis template
â”‚   â”œâ”€â”€ stage1_basic_exploration.txt
â”‚   â”œâ”€â”€ stage2_persona_analysis.txt
â”‚   â”œâ”€â”€ stage3_stress_exploration.txt
â”‚   â””â”€â”€ stage4_analysis.txt
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .env                        # API_KEY (gitignored)
â”œâ”€â”€ trajectories/               # Session data (gitignored)
â””â”€â”€ venv/                       # Virtual environment (gitignored)
```

> **ğŸ’¡ Note:** The app uses `index_new.html` and `script_new.js` for the enhanced interface with comparison features.

---

## ğŸ¨ Key Features Explained

### ğŸ”­ DroidScope Interface

<table>
<tr>
<td width="33%"><b>Monochrome Theme</b></td>
<td width="67%">Clean black & white design with subtle grid pattern background</td>
</tr>
<tr>
<td><b>Rounded Design</b></td>
<td>Consistent border-radius (8px-12px) across all UI elements</td>
</tr>
<tr>
<td><b>Card-Based Layout</b></td>
<td>Professional result cards with headers, badges, descriptions, and metadata</td>
</tr>
<tr>
<td><b>Dual SSE Streams</b></td>
<td>Separate endpoints for progress (<code>/api/progress</code>) and logs (<code>/api/logs</code>)</td>
</tr>
<tr>
<td><b>Agent Reasoning</b></td>
<td>Real-time stdout/stderr capture shows actual LLM chain-of-thought</td>
</tr>
</table>

### ğŸ“¡ Real-Time Updates

| Component | Description |
|-----------|-------------|
| **Progress Bar** | Shows completion percentage (0-100%) |
| **Terminal Logs** | Live execution events with timestamps |
| **Color-Coded** | Info (gray), Success (green), Warning (yellow), Error (red) |

### ğŸ¯ Category Intelligence

The system asks an LLM: *"What should I test in a [category] app?"*

<table>
<tr>
<td>âœ“</td>
<td>Generates context-specific testing goals</td>
</tr>
<tr>
<td>âœ“</td>
<td>Focuses on relevant features (e.g., checkout flow for e-commerce)</td>
</tr>
<tr>
<td>âœ“</td>
<td>Validates industry-specific UX patterns</td>
</tr>
</table>

### âœ… Device Verification

On startup, `verify_setup.py` runs `droidrun ping` to ensure:

- âœ“ Device/emulator is connected
- âœ“ DroidRun can communicate
- âœ“ App won't fail mid-exploration

### ğŸ“Š Balanced Analysis

<table>
<tr>
<th width="30%">Aspect</th>
<th>What's Analyzed</th>
</tr>
<tr>
<td>âœ… <b>Positive Patterns</b></td>
<td>What works well</td>
</tr>
<tr>
<td>âš ï¸ <b>Issues</b></td>
<td>Problems found</td>
</tr>
<tr>
<td>ğŸ’¡ <b>Suggestions</b></td>
<td>Actionable improvements</td>
</tr>
<tr>
<td>ğŸ“ˆ <b>Metrics</b></td>
<td>Quantitative measurements</td>
</tr>
</table>

### ğŸ”„ Advanced Comparison (NEW)

The comparison view provides comprehensive multi-app analysis:

<table>
<tr>
<th width="30%">Feature</th>
<th>Description</th>
</tr>
<tr>
<td>ğŸŸ¢ <b>Common Features</b></td>
<td>Automatically identifies patterns and features shared across all compared apps (e.g., "Bottom Navigation Bar", "Like Button")</td>
</tr>
<tr>
<td>ğŸ”µ <b>Distinct Features</b></td>
<td>Highlights unique aspects of each app that differentiate it from others</td>
</tr>
<tr>
<td>âœ… <b>What Went Good</b></td>
<td>Shows top 3 positive aspects per app with detailed descriptions and locations</td>
</tr>
<tr>
<td>âŒ <b>What's Bad</b></td>
<td>Issues categorized by severity:<br>
â€¢ <b style="color:red">High</b> - Critical UX problems<br>
â€¢ <b style="color:orange">Medium</b> - Moderate issues<br>
â€¢ <b style="color:green">Low</b> - Minor improvements
</td>
</tr>
<tr>
<td>ğŸ“Š <b>Metrics Dashboard</b></td>
<td>Displays UX Score, Complexity Score, Avg/Max Depth, Screens Discovered, Error Handling rating</td>
</tr>
<tr>
<td>ğŸ¨ <b>Visual Charts</b></td>
<td>Color-coded bar charts (green â‰¥8, yellow â‰¥6, red <6) with interactive tooltips</td>
</tr>
<tr>
<td>ğŸ“ˆ <b>Summary Stats</b></td>
<td>Overall comparison showing Average UX Score, Total Issues, Total Positives, Common Features count</td>
</tr>
</table>

**How to Use Comparison:**
1. Navigate to the **Compare** tab in the web interface
2. Select a **category** (e.g., Social Media, E-commerce)
3. Choose a **persona** (e.g., QA Engineer, Product Manager)
4. View side-by-side comparison of up to 5 apps
5. Analyze common patterns, unique features, and quality metrics

---

## âš™ï¸ Configuration & Customization

### ğŸ”„ Change LLM Model

Edit `.env` file:

```env
# Use a different model
LLM_MODEL=anthropic/claude-3.5-sonnet

# Or use OpenAI
LLM_MODEL=openai/gpt-4
LLM_API_BASE=https://api.openai.com/v1
```

**Supported providers:**
- OpenRouter (default) - Multiple models via single API
- OpenAI - Direct GPT models
- Any OpenAI-compatible endpoint

### ğŸ“ Customize Prompts

Edit files in `prompts/` folder:

| File | Purpose | Variables |
|------|---------|----------|
| `agent_goal.txt` | Exploration instructions with 12 data collection categories | `{app_name}`, `{category}` |
| `analysis_prompt_v2.txt` | Professional UX analysis criteria with comprehensive metrics | `{report_content}` |
| `html_generation_prompt.txt` | HTML report generation template | `{report_content}` |

**Note:** JSON examples in prompts must use escaped braces: `{{"key": "value"}}`

### ğŸ“ Adjust Exploration Depth

**Via web UI slider (3-12)** or in code:

```python
# exploration_runner.py
config.agent.max_steps = max_depth * 15  # Steps = depth Ã— 15
```

---

## ğŸ“‹ Requirements

<table>
<tr>
<td>ğŸ</td>
<td>Python 3.8+</td>
</tr>
<tr>
<td>ğŸ“±</td>
<td><a href="https://github.com/droidrun/droidrun">DroidRun framework</a></td>
</tr>
<tr>
<td>ğŸ”‘</td>
<td><a href="https://openrouter.ai">OpenRouter</a> API key (for free LLM access)</td>
</tr>
<tr>
<td>ğŸ“²</td>
<td>Android device/emulator with app installed</td>
</tr>
</table>

---

## ï¿½ Common Issues & Quick Fixes

| Problem | Quick Fix |
|---------|-----------|
| âŒ "Device not connected" | Run `adb devices` to check, then `droidrun ping` |
| ğŸ”‘ "API key not found" | Create `.env` file with `API_KEY=your_key` |
| ğŸ”Œ "Port 5000 in use" | Change port in [app.py](app.py): `app.run(port=5001)` |
| ğŸŒ Slow exploration | Reduce depth slider to 3-5 |
| ğŸ“Š No analysis generated | Check terminal logs and verify API key is valid |
| ğŸŒ UI not loading | Clear cache (`Ctrl+Shift+R`) or try another browser |
| ğŸ Venv won't activate | Run as admin: `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser` |
| ğŸ“± Wrong app opens | Use display name, not package name (e.g., "Instagram") |

**Still stuck?** See detailed troubleshooting section above â¬†ï¸

---

## ï¿½ğŸ”š Deactivate Virtual Environment

When done:

```powershell
deactivate
```

---

<div align="center">

## ğŸ“„ License

**MIT License** - Feel free to use, modify, and distribute.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to submit issues or pull requests.

### Contributors

- **Shashank Bharti** - Core Development
- **Sudhanshu Kumar** - Core Development
- **Sumit Kumar** - UI Design and Research

---

<p>
Made with ğŸ«€ by Team LastCrusade 
</p>

</div>
